#{.tabset .tabset-fade .tabset-pills}


Desarrollo de los ejercicios del capitulo IV del libro _"Una introducción al aprendizaje estadistico con aplicaciones en R"_

## Punto 4

* **Genere un conjunto de datos simulados de dos clases con 100 observaciones y dos características en las que haya una separación visible pero no lineal entre las dos clases. Muestre que en esta configuración, una máquina de vectores de soporte con un núcleo polinomial (con un grado mayor que 1) o un núcleo radial superará a un clasificador de vectores de soporte en los datos de entrenamiento. ¿Qué técnica funciona mejor en los datos de prueba? Haga tramas e informe la capacitación y pruebe las tasas de error para respaldar sus afirmaciones.**

```{r}
library(e1071)
set.seed(1)
x <- rnorm(100)
y <- 4 * x^3 + 1 + rnorm(100)
clase <- sample(100, 50)
y[clase] <- y[clase] + 3
y[-clase] <- y[-clase] - 3
plot(x[clase], y[clase], col = "green", xlab = "X", ylab = "Y", ylim = c(-10, 25), xlim = c(-1.5, 2.0))
points(x[-clase], y[-clase], col = "blue")
```

Clasificador de soporte en los datos de entrenamiento

```{r}
z <- rep(-1, 100)
z[clase] <- 1
data <- data.frame(x = x, y = y, z = as.factor(z))
train <- sample(100, 50)
data.train <- data[train, ]
data.test <- data[-train, ]
svm.linear <- svm(z ~ ., data = data.train, kernel = "linear", cost = 10)
plot(svm.linear, data.train)
```

```{r}
table(predict = predict(svm.linear, data.train), truth = data.train$z)
```

El clasificador de vectores de soporte comete 4 errores en los datos de entrenamiento.

Maquina de vectores de soporte con un núcleo polinomial.



```{r}
svm.poly <- svm(z ~ ., data = data.train, kernel = "polynomial", cost = 10)
plot(svm.poly, data.train)
```


```{r}
table(predict = predict(svm.poly, data.train), truth = data.train$z)
```

La máquina de vectores de soporte comete 2 errores en los datos de entrenamiento.

```{r}
svm.radial <- svm(z ~ ., data = data.train, kernel = "radial", gamma = 1, cost = 10)
plot(svm.radial, data.train)
```

```{r}
table(predict = predict(svm.radial, data.train), truth = data.train$z)
```

La máquina con un núcleo radial comete  0  errores en los datos de entrenamiento.

Aplicando a los datos de prueba.

```{r}
plot(svm.linear, data.test)
```

```{r}
table(predict = predict(svm.linear, data.test), truth = data.test$z)
```
```{r}
plot(svm.poly, data.test)
```

```{r}
table(predict = predict(svm.poly, data.test), truth = data.test$z)
```

```{r}
plot(svm.radial, data.test)
```

```{r}
table(predict = predict(svm.radial, data.test), truth = data.test$z)
```

Como vemos en los resultados anteriores, las máquinas de vectores de soporte lineal, polinomial y radial clasifican, respectivamente 4, 2 y 0 observaciones de forma incorrecta. Entonces, el núcleo radial es el mejor modelo en este caso.

## Punto 5

* **Hemos visto que podemos ajustar un SVM con un núcleo no lineal para realizar la clasificación utilizando un límite de decisión no lineal. Ahora veremos que también podemos obtener un límite de decisión no lineal al realizar una regresión logística utilizando transformaciones no lineales de las características.**


**(a) Genere un conjunto de datos con n = 500 y p = 2, de modo que las observaciones pertenezcan a dos clases con un límite de decisión cuadrático entre ellas. Por ejemplo, puede hacer esto de la siguiente manera:**

**> x1 = runif (500) -0.5**

**> x2 = runif (500) -0.5**

**> y = 1 * (x1 ^ 2-x2 ^ 2> 0)**

```{r}
set.seed(1)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
```


**(b) Grafique las observaciones, coloreadas de acuerdo con sus etiquetas de clase. Su diagrama debe mostrar X1 en el eje xy X2 en el eje y.**

```{r}
plot(x1, x2, xlab = "X1", ylab = "X2", col = (5 - y), pch = (2 - y))
```


**(c) Ajuste un modelo de regresión logística a los datos, utilizando X1 y X2 como predictores.**

```{r}
logit.fit <- glm(y ~ x1 + x2, family = "binomial")
summary(logit.fit)
```

Ninguna de las variables es estadísticamente significativa.

**(d) Aplique este modelo a los datos de entrenamiento para obtener una etiqueta de clase predicha para cada observación de entrenamiento. Trace las observaciones, coloreadas de acuerdo con las etiquetas de clase predichas. El límite de decisión debe ser lineal.**

```{r}
data <- data.frame(x1 = x1, x2 = x2, y = y)
probs <- predict(logit.fit, data, type = "response")
preds <- rep(0, 500)
preds[probs > 0.47] <- 1
plot(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (6 - 1), pch = (2 - 1), xlab = "X1", ylab = "X2")
points(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (4 - 0), pch = (2 - 0))
```

El límite de decisión es lineal.

**(e) Ahora ajuste un modelo de regresión logística a los datos utilizando funciones no lineales de X1 y X2 como predictores (por ejemplo, X12, X1 × X2, log (X2), etc.).**

```{r}
logitnl.fit <- glm(y ~ poly(x1, 2) + poly(x2, 2) + I(x1 * x2), family = "binomial")
```

```{r}
summary(logitnl.fit)
```

De nuevo ninguna de las variables son estadisticamente significativas


**(f) Aplique este modelo a los datos de entrenamiento para obtener una etiqueta de clase predicha para cada observación de entrenamiento. Trace las observaciones, coloreadas de acuerdo con las etiquetas de clase predichas. El límite de decisión debe ser obviamente no lineal. Si no es así, repita (a) - (e) hasta que encuentre un ejemplo en el que las etiquetas de clase predichas sean obviamente no lineales.**

```{r}
probs <- predict(logitnl.fit, data, type = "response")
preds <- rep(0, 500)
preds[probs > 0.47] <- 1
plot(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (6 - 1), pch = (2 - 1), xlab = "X1", ylab = "X2")
points(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (4 - 0), pch = (2 - 0))
```

El límite de decisión no lineal es muy similar al límite de decisión real.


**(g) Ajuste un clasificador de vector de soporte a los datos con X1 y X2 como predictores. Obtenga una predicción de clase para cada observación de entrenamiento. Trace las observaciones, coloreadas de acuerdo con las etiquetas de clase predichas.**

```{r}
data$y <- as.factor(data$y)
svm.fit <- svm(y ~ x1 + x2, data, kernel = "linear", cost = 0.01)
preds <- predict(svm.fit, data)
plot(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (5 - 0), pch = (2 - 0), xlab = "X1", ylab = "X2")
points(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (4 - 1), pch = (2 - 1))
```

Este clasificador de vectores de soporte clasifica todos los puntos en una sola clase.

**(h) Ajuste un SVM usando un núcleo no lineal a los datos. Obtenga una predicción de clase para cada observación de entrenamiento. Trace las observaciones, coloreadas de acuerdo con las etiquetas de clase predichas.**

```{r}
data$y <- as.factor(data$y)
svmnl.fit <- svm(y ~ x1 + x2, data, kernel = "radial", gamma = 1)
preds <- predict(svmnl.fit, data)
plot(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (5 - 0), pch = (1 - 0), xlab = "X1", ylab = "X2")
points(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (5 - 1), pch = (2 - 1))
```

De nuevo el límite de decisión no lineal es muy similar al límite de decisión verdadero.

**(i) Comente sus resultados.**

Con los anteriores resultados podemos concluir que las maquinas de soporte con metodos no lineal y regresión logística con términos de interacción son muy efectivas. 

## Punto 6

* **Al final de la Sección 9.6.1, se afirma que, en el caso de los datos que son apenas linealmente separables, un clasificador de vectores de soporte con un pequeño valor de costo que clasifica erróneamente un par de observaciones de entrenamiento puede funcionar mejor en los datos de prueba que uno con un enorme valor de costo que no clasifica erróneamente ninguna observación de capacitación. Ahora investigará este reclamo.**

**(a) Genere datos de dos clases con p = 2 de tal manera que las clases sean apenas separables linealmente.**

```{r}
set.seed(123)
x.uno <- runif(500, 0, 90)
y.uno <- runif(500, x.uno + 10, 100)
x.uno.noise <- runif(50, 20, 80)
y.uno.noise <- 5/4 * (x.uno.noise - 10) + 0.1

x.cero <- runif(500, 10, 100)
y.cero <- runif(500, 0, x.cero - 10)
x.cero.noise <- runif(50, 20, 80)
y.cero.noise <- 5/4 * (x.cero.noise - 10) - 0.1

clase.uno <- seq(1, 550)
x <- c(x.uno, x.uno.noise, x.cero, x.cero.noise)
y <- c(y.uno, y.uno.noise, y.cero, y.cero.noise)

plot(x[clase.uno], y[clase.uno], col = "blue", pch = 5, ylim = c(0, 100))
points(x[-clase.uno], y[-clase.uno], col = "lightblue", pch = 5)
```


**(b) Calcule las tasas de error de validación cruzada para los clasificadores de vectores de soporte con un rango de valores de costo. ¿Cuántos errores de capacitación están mal clasificados para cada valor de costo considerado, y cómo se relaciona esto con los errores de validación cruzada obtenidos?**

```{r}
set.seed(123)
z <- rep(0, 1100)
z[clase.uno] <- 1
data <- data.frame(x = x, y = y, z = as.factor(z))
tune.out <- tune(svm, z ~ ., data = data, kernel = "linear", ranges = list(cost = c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)))
summary(tune.out)
```
 El mejor parametro parece ser el que se obtiene con 10000

```{r}
data.frame(cost = tune.out$performance$cost, misclass = tune.out$performance$error * 1100)
```

Podemos ver como 10000 tiene cero errores al clasificar los puntos 

**(c) Genere un conjunto de datos de prueba apropiado y calcule los errores de prueba correspondientes a cada uno de los valores de costo considerados. ¿Qué valor del costo conduce a la menor cantidad de errores de prueba, y cómo se compara esto con los valores de costo que producen la menor cantidad de errores de capacitación y la menor cantidad de errores de validación cruzada?**

```{r}
x.test <- runif(1000, 0, 100)
clase.uno <- sample(1000, 500)
y.test <- rep(NA, 1000)

for (i in clase.uno) {
    y.test[i] <- runif(1, x.test[i], 100)
}

for (i in setdiff(1:1000, clase.uno)) {
    y.test[i] <- runif(1, 0, x.test[i])
}
plot(x.test[clase.uno], y.test[clase.uno], col = "blue", pch = 5)
points(x.test[-clase.uno], y.test[-clase.uno], col = "lightblue", pch = 5)

```
```{r}
set.seed(123)
z.test <- rep(0, 1000)
z.test[clase.uno] <- 1
data.test <- data.frame(x = x.test, y = y.test, z = as.factor(z.test))
costos <- c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)
test.err <- rep(NA, length(costos))
for (i in 1:length(costos)) {
    svm.fit <- svm(z ~ ., data = data, kernel = "linear", cost = costos[i])
    pred <- predict(svm.fit, data.test)
    test.err[i] <- sum(pred != data.test$z)
}
data.frame(cost = costos, misclass = test.err)
```

Los costos de  5 o 10 parecen funcionar mejor en las observaciones de prueba

**(d) Discuta sus resultados.**

Pdemos ver como un costo grande intenta clasificar correctamente los puntos, sin embargo, un pequeño costo hace algunos errores en los puntos de prueba y funciona mejor en los datos.

## Punto 7

* **En este problema, utilizará enfoques de vectores de soporte para predecir si un automóvil determinado obtiene un millaje de gasolina alto o bajo en función del conjunto de datos automático.**



**(a) Cree una variable binaria que tome un 1 para los automóviles con millaje de gasolina por encima de la mediana, y un 0 para automóviles con millaje de gasolina por debajo de la mediana.**
```{r}
require(ISLR)
library(ISLR)
var <- ifelse(Auto$mpg > median(Auto$mpg), 1, 0)
Auto$mpglevel <- as.factor(var)
```



**(b) Ajuste un clasificador de vector de soporte a los datos con varios valores de costo, para predecir si un automóvil obtiene un millaje de gasolina alto o bajo. Informe los errores de validación cruzada asociados con diferentes valores de este parámetro. Comenta tus resultados.**

```{r}
require(e1071)

set.seed(123)
tune.out <- tune(svm, mpglevel ~ ., data = Auto, kernel = "linear", ranges = list(cost = c(0.01, 0.1, 1, 5, 10, 100, 1000)))
summary(tune.out)
```

Un costo de 1 es el que parece funionar mejor ya que es el que tiene menor error

**(c) Ahora repita (b), esta vez usando SVM con núcleos de base radial y polinomial, con diferentes valores de gamma y grado y costo. Comenta tus resultados.**
```{r}
set.seed(1)
tune.out <- tune(svm, mpglevel ~ ., data = Auto, kernel = "polynomial", ranges = list(cost = c(0.01, 0.1, 1, 5, 10, 100), degree = c(2, 3, 4)))
summary(tune.out)
```

El error de validación cruzada más bajo se obtiene para un grado de 2 y un costo de 100.




```{r}
set.seed(123)
tune.out <- tune(svm, mpglevel ~ ., data = Auto, kernel = "radial", ranges = list(cost = c(0.01, 0.1, 1, 5, 10, 100), gamma = c(0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
```
El error de validación cruzada más bajo se obtiene para una gamma de 0.01 y un costo de 100.

**(d) Haga algunos gráficos para respaldar sus afirmaciones en (b) y (c). Sugerencia: En el laboratorio, utilizamos la función plot() para objetos svm solo en casos con p = 2. Cuando p> 2, puede usar la función plot() para crear gráficos que muestren pares de variables a la vez. Esencialmente, en lugar de escribir**

**> plot (svmfit, dat)**

**donde svmfit contiene su modelo ajustado y dat es un marco de datos que contiene sus datos, puede escribir**

**> plot (svmfit, dat, x1∼x4)**

**para graficar solo las variables primera y cuarta. Sin embargo, debe reemplazar x1 y x4 con los nombres correctos de las variables. Para obtener más información, escriba ?Plot.svm.**

```{r}
svm.linear <- svm(mpglevel ~ ., data = Auto, kernel = "linear", cost = 1)
svm.poly <- svm(mpglevel ~ ., data = Auto, kernel = "polynomial", cost = 100, degree = 2)
svm.radial <- svm(mpglevel ~ ., data = Auto, kernel = "radial", cost = 100, gamma = 0.01)
plotpairs = function(fit) {
    for (name in names(Auto)[!(names(Auto) %in% c("mpg", "mpglevel", "name"))]) {
       plot(fit, Auto, as.formula(paste("mpg~", name, sep = "")))
    }
}
plotpairs(svm.linear)
```
```{r}
plotpairs(svm.poly)
```
```{r}
plotpairs(svm.radial)
```


## Punto 8


* **Este problema involucra el conjunto de datos de OJ que es parte del paquete ISLR.**

**(a) Cree un conjunto de entrenamiento que contenga una muestra aleatoria de 800 observaciones, y un conjunto de prueba que contenga las observaciones restantes.**

```{r}
set.seed(123)
train <- sample(nrow(OJ), 800)
OJ.train <- OJ[train, ]
OJ.test <- OJ[-train, ]
```


**(b) Ajuste un clasificador de vector de soporte a los datos de entrenamiento usando cost = 0.01, con Compra como respuesta y las otras variables como predictores. Use la función summary() para generar estadísticas resumidas y describir los resultados obtenidos.**
```{r}
svm.linear <- svm(Purchase ~ ., data = OJ.train, kernel = "linear", cost = 0.01)
summary(svm.linear)
```
 El clasificador de vectores de soporte crea 442 vectores de soporte. De estos, 220 pertenecen al nivel CH y los 222 restantes pertenecen al nivel MM.


**(c) ¿Cuáles son las tasas de error de capacitación y prueba?**

```{r}
train.pred <- predict(svm.linear, OJ.train)
table(OJ.train$Purchase, train.pred)
```

(71 + 61) / (426 + 242 + 71 + 61)

```{r}
test.pred <- predict(svm.linear, OJ.test)
table(OJ.test$Purchase, test.pred)
```

(27 + 21) / (145 + 77 + 27 + 21)

 La tasa de error de entrenamiento es de 16.5% y la tasa de error de prueba es de aproximadamente 17.7%.

**(d) Use la función tune() para seleccionar un costo óptimo. Considere values en el rango de 0.01 a 10.**

```{r}
set.seed(123)
tune.out <- tune(svm, Purchase ~ ., data = OJ.train, kernel = "linear", ranges = list(cost = 10^seq(-2, 1, by = 0.25)))
summary(tune.out)

```
Podemos ver que el costo optimo es de 3.16

**(e) Calcule las tasas de error de entrenamiento y prueba usando este nuevo valor por el cost**
```{r}
svm.linear <- svm(Purchase ~ ., kernel = "linear", data = OJ.train, cost = tune.out$best.parameter$cost)
train.pred <- predict(svm.linear, OJ.train)
table(OJ.train$Purchase, train.pred)
```

(69 + 60) / (427 + 244 + 69 + 60)

```{r}
test.pred <- predict(svm.linear, OJ.test)
table(OJ.test$Purchase, test.pred)
```

(25 + 17) / (149 + 79 + 25 + 17)

Podemos ver que, con el mejor costo, la tasa de error de entrenamiento es ahora del 16.1% y la tasa de error de la prueba es del 15.5%.

**(f) Repita las partes (b) a (e) usando una máquina de vectores de soporte con un núcleo radial Use el valor predeterminado para gamma.**

```{r}
svm.radial <- svm(Purchase ~ ., kernel = "radial", data = OJ.train)
summary(svm.radial)
```

```{r}
train.pred <- predict(svm.radial, OJ.train)
table(OJ.train$Purchase, train.pred)
```

(70 + 41) / (446 + 243 + 70 + 41)

```{r}
test.pred <- predict(svm.radial, OJ.test)
table(OJ.test$Purchase, test.pred)
```

(34 + 17) / (149 + 70 + 34 + 17)

El clasificador tiene un error de entrenamiento del 13.8% y un error de prueba del 18.8%.
```{r}
set.seed(123)
tune.out <- tune(svm, Purchase ~ ., data = OJ.train, kernel = "radial", ranges = list(cost = 10^seq(-2, 
    1, by = 0.25)))
summary(tune.out)
```
```{r}
svm.radial <- svm(Purchase ~ ., kernel = "radial", data = OJ.train, cost = tune.out$best.parameter$cost)
summary(svm.radial)
```
```{r}
train.pred <- predict(svm.radial, OJ.train)
table(OJ.train$Purchase, train.pred)
```

(77 + 44) / (441 + 238 + 77 + 44)

```{r}
test.pred <- predict(svm.radial, OJ.test)
table(OJ.test$Purchase, test.pred)
```

(34 + 17) / (149 + 70 + 34 + 17)

El ajuste no reduce las tasas de error de tren y prueba


**(g) Repita las partes (b) a (e) usando una máquina de vectores de soporte con un núcleo polinomial Establecer grado = 2.**
```{r}
svm.poly <- svm(Purchase ~ ., kernel = "polynomial", data = OJ.train, degree = 2)
summary(svm.poly)
```
```{r}
train.pred <- predict(svm.poly, OJ.train)
table(OJ.train$Purchase, train.pred)
```
(105 + 33) / (454 + 208 + 105 + 33)

```{r}
test.pred <- predict(svm.poly, OJ.test)
table(OJ.test$Purchase, test.pred)
```

(47 + 13) / (153 + 57 + 47 + 13)

El clasificador tiene un error de entrenamiento del 17.2% y un error de prueba del 22.2%, lo que no mejora el núcleo lineal.

```{r}
set.seed(123)
tune.out <- tune(svm, Purchase ~ ., data = OJ.train, kernel = "polynomial", degree = 2, ranges = list(cost = 10^seq(-2, 
    1, by = 0.25)))
summary(tune.out)
```

```{r}
svm.poly <- svm(Purchase ~ ., kernel = "polynomial", degree = 2, data = OJ.train, cost = tune.out$best.parameter$cost)
summary(svm.poly)
```

```{r}
train.pred <- predict(svm.poly, OJ.train)
table(OJ.train$Purchase, train.pred)
```

(87 + 35) / (452 + 226 + 87 + 35)

```{r}
test.pred <- predict(svm.poly, OJ.test)
table(OJ.test$Purchase, test.pred)
```

(41 + 15) / (151 + 63 + 41 + 15)

El ajuste reduce las tasas de error de entreno y prueba.

**(h) En general, ¿qué enfoque parece dar los mejores resultados con estos datos?**

En general, el núcleo de base radial parece estar produciendo un error mínimo de clasificación errónea en los datos del tren y de la prueba.
