#{.tabset .tabset-fade .tabset-pills}


Desarrollo de los ejercicios del capitulo IV del libro _"Una introducción al aprendizaje estadistico con aplicaciones en R"_




## Punto 7

*  **En el laboratorio, aplicamos bosques aleatorios a los datos de Boston usando mtry = 6 y usando ntree = 25 y ntree = 500. Cree un gráfico que muestre el error de prueba resultante de bosques aleatorios en este conjunto de datos para un rango de valores más amplio para mtry y ntree. Puede modelar su diagrama después de la Figura 8.10. Describa los resultados obtenidos.**

```{r}
library(MASS)
library(randomForest)
train <- sample(1:nrow(Boston),length(Boston$crim)*0.70,replace = FALSE)
data.train <- Boston[train,-14]
data.test <- Boston[-train,-14]
y.train <- Boston[train,14]
y.test <- Boston[-train,14]
set.seed(0511)
boston.1 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
                         ntree = 500,mtry = ncol(Boston)-1)

boston.2 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
                         ntree = 500,mtry = (ncol(Boston)-1)/2)

boston.3 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
                         ntree = 500,mtry = sqrt(ncol(Boston)-1))

val <- data.frame(arboles = 1:500)
val["MSE1"] <- boston.1$test$mse
val["MSE2"] <- boston.2$test$mse
val["MSE3"] <- boston.3$test$mse

library(ggplot2)
library(reshape2)
xy <- melt(val,id=c("arboles"))

theme_set(theme_bw())
ggplot(xy)+geom_line(aes(x=arboles,y = value,color=variable))+
  scale_color_manual(name=" m = ",labels=c("p","p/2","\u221Ap"),values = c("orange","red","green"))+labs(x = "Número de árboles",
       y = "Error de clasificación") +
  theme(legend.position="top")


```

Con esta grafica podemos observar que la prueba MSE es muy alta para un solo arbol, a mededida que aunmenta los arboles el error se estabiliza aproximademente cuando hay 150 arboles, La estaibilización se presenta para los tres valores de "m". El m que menor reprensenta error es m = $sqrt(p)$.Ojo que al variar la semilla se podra concluir diferente.



## Punto 8


*  **En el laboratorio, se aplicó un árbol de clasificación al conjunto de datos de Carseats después de convertir las ventas en una variable de respuesta cualitativa. Ahora buscaremos predecir las ventas utilizando árboles de regresión y enfoques relacionados, tratando la respuesta como una variable cuantitativa.**

**(a) Divida el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba.**

```{r}
library(ISLR)
set.seed(0511)
train <- sample(1:nrow(Carseats),nrow(Carseats)*0.65,replace = FALSE)
carseats.train <- Carseats[train,]
carseats.test <- Carseats[-train,]

```


**(b) Ajuste un árbol de regresión al conjunto de entrenamiento. Trace el árbol e interprete los resultados. ¿Qué prueba MSE obtienes?**

```{r}

library(rpart)
library(rpart.plot)
carseats.tree <- rpart(Sales~.,data = carseats.train)
rpart.plot(carseats.tree,box.palette = "RdBu",nn=TRUE)


```

```{r}
pred <- predict(carseats.tree,carseats.test)
mean((pred - carseats.test$Sales)^2)


```
con el anterior resultado concluimos que el MSE es aproximadamente de 5.46.


**(c) Utilice la validación cruzada para determinar el nivel óptimo de complejidad del árbol. ¿La poda del árbol mejora la prueba MSE?**



```{r}
printcp(carseats.tree)
```
```{r}
plotcp(carseats.tree)
```
```{r}
min <- which.min(carseats.tree$cptable[,"xerror"])
print(min)

```
```{r}
cpt <- carseats.tree$cptable[which.min(carseats.tree$cptable[,"xerror"]),"CP"]
cpt
```
con la validación cruzada obtenemos un tamaño de arbol igual a 13 y un cp de 0.01357961

```{r}
ptree <- prune(carseats.tree,cp = cpt)
rpart.plot(ptree,box.palette = "RdBu",nn=TRUE)
```

```{r}
pred1 <- predict(ptree,newdata = carseats.test)
m2 <- mean((pred1-carseats.test$Sales)^2)
m2
```
Se disminuye  el MSE despues de que se poda.


**(d) Utilice el enfoque de embolsado para analizar estos datos. ¿Qué prueba MSE obtienes? Use la función importance() para determinar qué variables son más importantes.**


```{r}
bag.carseats <- randomForest(Sales~.,carseats.train,mtry=(ncol(Carseats)-1) ,importance=TRUE)
pred2 <- predict(bag.carseats,newdata = carseats.test)
mean((pred2- carseats.test$Sales)^2)
```
notablemente mejora el MSE a 3.37627.


```{r}
importance(bag.carseats)
```
Se puede concluir con lo anterior que Price,Shelveloc,CompPrice son variables importantes para este analisis.

**(e) Utilice bosques aleatorios para analizar estos datos. ¿Qué prueba MSE obtienes? Use la función importance() para determinar qué variables son las más importantes. Describa el efecto de m, el número de variables consideradas en cada división, sobre la tasa de error obtenida.**


```{r}
bag.carseats <- randomForest(Sales ~ ., data = carseats.train, mtry = sqrt((ncol(Carseats) - 1)), importance = TRUE)
pred.bag <- predict(bag.carseats, newdata = carseats.test)
mean((pred.bag - carseats.test$Sales)^2)
```
Con lo anterior tenemos un MSE de 3.38
```{r}
importance(bag.carseats)
```
Con lo anterior cuncluimos que las mejores varibales predictoras para el analisis son las mismas que el numeral anterior.


## Punto 9

* **Este problema involucra el conjunto de datos de OJ que es parte del paquete ISLR.**

**(a) Cree un conjunto de entrenamiento que contenga una muestra aleatoria de 800 observaciones, y un conjunto de prueba que contenga las observaciones restantes.**
```{r}
train <- sample(x = 1:nrow(OJ),size = 800)
OJ.train <- OJ[train,]
OJ.test <- OJ[-train,]

```



**(b) Ajuste un árbol a los datos de entrenamiento, con Compra como respuesta y las otras variables como predictores. Use la función summary() para generar estadísticas resumidas sobre el árbol y describa los resultados obtenidos. ¿Cuál es la tasa de error de entrenamiento? ¿Cuántos nodos terminales tiene el árbol?**


```{r}
set.seed(0511)
library(tree)
tree.oj <- tree(Purchase~.,data = OJ.train)
summary(tree.oj)

```
Este arbalo tiene 8 nodos terminales y una tasa de error de entrenamiento de 0.1612


**(c) Escriba el nombre del objeto del árbol para obtener una salida de texto detallada. Elija uno de los nodos terminales e interprete la información que se muestra.**

```{r}
tree.oj
```
Escogemos el nodo terminal 15, debido a que es un nodo terminal debido al asterisco.apreciamos que su criterio de división es LoyalCH > 0.764572 esta tiene 254 observaciones en este nodo y una desviación estandar 64.090. La predicción general para la rama CH,también podemos ver que el 97.24% de las observaciones toman el valor de CH, mientras que el 0.02756 tomal el valor de MM.

**(d) Cree un diagrama del árbol e interprete los resultados.**

```{r}

plot(tree.oj)
text(tree.oj, pretty = 0)
```
Podemos apreciar que el nodo principal es LoyalCH si es menor o igual a 0.50 solo usa a su misma variables , pero si es menor utiliza a PriceDiff.


**(e) Predecir la respuesta en los datos de prueba, y producir una matriz de confusión comparando las etiquetas de prueba con las etiquetas de prueba predichas. ¿Cuál es la tasa de error de prueba?**


```{r}
library(caret)
tree.pred <- predict(tree.oj, OJ.test, type = "class")

matrix<-confusionMatrix(tree.pred, OJ.test$Purchase)
matrix
```
Observamos que la precisión del modelo es de 82.89%, siendo mas preciso para predecir a CH con un 90.65% mientras que para predecir MM sólo es de un 70.91%.
**(f) Aplique la función cv.tree() al conjunto de entrenamiento para determinar el tamaño óptimo del árbol.**

```{r}
cv.oj <- cv.tree(tree.oj,FUN = prune.misclass)
cv.oj
```


**(g) Produzca un diagrama con el tamaño del árbol en el eje xy la tasa de error de clasificación con validación cruzada en el eje y.**

```{r}
library(ggplot2)
library(reshape2)
valores <- data.frame(Size=cv.oj$size,Dev=cv.oj$dev)
theme_set(theme_bw())
ggplot(data = valores, aes(x=Size, y=Dev)) + 
  geom_line(color="red", linetype = "dashed") +
  geom_point() +
  scale_x_discrete(limits=c(1:9))

```



**(h) ¿Qué tamaño de árbol corresponde a la tasa de error de clasificación con validación cruzada más baja?**
 5 es el tamaño con menor error 

**(i) Produzca un árbol podado correspondiente al tamaño óptimo del árbol obtenido mediante validación cruzada. Si la validación cruzada no conduce a la selección de un árbol podado, cree un árbol podado con cinco nodos terminales.**


```{r}
prune.oj <- prune.misclass(tree.oj,best = 5)
plot(prune.oj)
text(prune.oj,pretty = 0)
```

**(j) Compare las tasas de error de entrenamiento entre los árboles podados y no podados. ¿Cuál es más alto?**

```{r}
summary(prune.oj)
```

```{r}
summary(tree.oj)
```
observamos que hay una diferencia en el erro mayor el arbol podado. 
**(k) Compare las tasas de error de prueba entre los árboles podados y no podados. ¿Cuál es más alto?**

```{r}
prune.pred <- predict(prune.oj, OJ.test, type = "class")

matrix<-confusionMatrix(prune.pred, OJ.test$Purchase)
matrix
```
observamos que bajo la presicion del modelo notablemente con respecto al árbol sin podar.


## Punto 10

* **Ahora usamos el aumento para predecir el salario en el conjunto de datos de Hitters.**

**(a) Elimine las observaciones para las que se desconoce la información salarial, y luego transforme logarítmicamente los salarios.**


```{r}
Hitters <- na.omit(Hitters)
Hitters$Salary <- log(Hitters$Salary)

```

**(b) Cree un conjunto de entrenamiento que consista en las primeras 200 observaciones, y un conjunto de prueba que consista en las observaciones restantes.**

```{r}
train <- 1:200
Hitters.train <- Hitters[train,]
Hitters.test <- Hitters[-train,]
```


**(c) Realice un refuerzo en el conjunto de entrenamiento con 1,000 árboles para un rango de valores del parámetro de contracción $\lambda$. Produzca un gráfico con diferentes valores de contracción en el eje xy el conjunto de entrenamiento MSE correspondiente en el eje y.**


```{r}
library(gbm)
set.seed(0511)
lambdas = seq(0.001, 0.3, 0.005)
mse <- rep(0, length(lambdas))
for (i in 1:length(lambdas)) {
  boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
    pred.train <- predict(boost.hitters, Hitters.train, n.trees = 1000)
    mse[i] <- mean((pred.train - Hitters.train$Salary)^2)
}
```
```{r}
library(ggplot2)

mse_graph <- data.frame(lambdas)
mse_graph["MSE"]<- mse
names(mse_graph) <- c("Lambdas", "MSE")

theme_set(theme_bw()) 
ggplot(data = mse_graph, aes(x = Lambdas, y = MSE)) +
  geom_line(color="red", linetype = "dashed") +
  geom_point() 
```


**(d) Produzca un gráfico con diferentes valores de contracción en el eje xy el conjunto de prueba MSE correspondiente en el eje y.**

```{r}
mse2 <- rep(NA, length(lambdas))
for (i in 1:length(lambdas)) {
    boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
    yhat <- predict(boost.hitters, Hitters.test, n.trees = 1000)
    mse2[i] <- mean((yhat - Hitters.test$Salary)^2)
}
```

```{r}
library(ggplot2)

mse_graph2 <- data.frame(lambdas)
mse_graph2["MSE"]<- mse2
names(mse_graph2) <- c("Lambdas", "MSE")

theme_set(theme_bw()) 
ggplot(data = mse_graph2, aes(x = Lambdas, y = MSE)) +
  geom_line(color="red", linetype = "dashed") +
  geom_point() 
```

```{r}
min(mse2)
```
```{r}
lambdas[which.min(mse2)]
```


**(e) Compare la prueba MSE de refuerzo con la prueba MSE que resulta de aplicar dos de los enfoques de regresión vistos en los Capítulos 3 y 6.**


```{r}
mod8.10 <- lm(Salary~.,data = Hitters.train)
pred8.10 <- predict(mod8.10,Hitters.test)
mean((pred8.10-Hitters.test$Salary)^2)
```

```{r}

library(pls)
pcr.fit=pcr(Salary~., data=Hitters.train , scale=TRUE , validation ="CV")
validationplot(pcr.fit ,val.type="MSEP")

```

```{r}
pcr.pred=predict (pcr.fit ,Hitters.test,ncomp =1)
mean((pcr.pred -Hitters.test$Salary)^2)
```
observamos que el MSE de la regresion lineal y de las componentes principales es mayor el MSE por el metodo Boosting 

**(f) ¿Qué variables parecen ser los predictores más importantes en el modelo impulsado?**
```{r}
boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[which.min(mse2)])
summary(boost.hitters)
```
En la tabla se observa que la variable mas importante es CatBat.

**(g) Ahora aplique el embolsado al conjunto de entrenamiento. ¿Cuál es el conjunto de prueba MSE para este enfoque?**


```{r}
bag.hitters <- randomForest(Salary ~ ., data = Hitters.train, mtry = 19)
yhat.bag <- predict(bag.hitters, newdata = Hitters.test)
mean((yhat.bag - Hitters.test$Salary)^2)
```
El MSE es de 0.2339 es mucho mejor que los otros metodos por el momento.
## Punto 11

* **Esta pregunta utiliza el conjunto de datos de Caravan.**

**(a) Cree un conjunto de entrenamiento que consista en las primeras 1,000 observaciones,y un conjunto de prueba que consta de las observaciones restantes.**


```{r}
library(ISLR)
data(Caravan)
set.seed(1)
train <- 1:1000
Caravan$Purchase <- ifelse(Caravan$Purchase=="Yes",1,0)

Caravan.train <- Caravan[train,]
Caravan.test <- Caravan[-train,]

```


**(b) Ajuste un modelo de refuerzo al conjunto de entrenamiento con Compra como respuesta y las otras variables como predictores. Use 1,000 árboles y un valor de contracción de 0.01. ¿Qué predictores parecen ser los más importantes?**

```{r}
set.seed(0511)
library(gbm)
boost.caravan <- gbm(Purchase~.,data = Caravan.train,distribution = "gaussian",
                     n.trees = 1000,shrinkage = 0.01)

summary(boost.caravan)
```
En la tabla observamos PPERSAUT y MKOOPKLA son las mas importantes.

**(c) Utilice el modelo de refuerzo para predecir la respuesta en los datos de la prueba. Predecir que una persona realizará una compra si la probabilidad estimada de compra es superior al 20%. Forme una matriz de confusión. ¿Qué fracción de las personas que predijeron hacer una compra en realidad la hacen? ¿Cómo se compara esto con los resultados obtenidos al aplicar KNN o regresión logística a este conjunto de datos?**

<<<<<<< HEAD
```{r}
library(caret)
probs.test <- predict(boost.caravan,Caravan.test,n.trees = 1000,type = "response")

predict.test <- ifelse( probs.test > 0.2, 1 , 0)
matrixx <- confusionMatrix(as.factor(predict.test),as.factor(Caravan.test$Purchase))
matrixx
```

Observamos que la personas que en realidad harán una compra la predicción tiene un precisión del 4.15%

```{r}
logit.caravan <- glm(Purchase ~ ., data = Caravan.train, family = "binomial")
```
```{r}
probs.test2 <- predict(logit.caravan,Caravan.test,type = "response")
pred.test2 <- ifelse(probs.test > 0.2, 1, 0)
matriz <- confusionMatrix(as.factor(pred.test2), as.factor(Caravan.test$Purchase))
matriz
```
Utilizando la regresion logística para predecir las personas que realmente hicieron una compra tiene un apresición de 4.1%.

## Punto 12

* **Aplique impulso, embolsado y bosques aleatorios a un conjunto de datos de su elección. Asegúrese de ajustar los modelos en un conjunto de entrenamiento y evaluar su desempeño en un conjunto de prueba. ¿Cuán precisos son los resultados en comparación con métodos simples como la regresión lineal o logística? ¿Cuál de estos enfoques produce el mejor rendimiento?**


Uitilizando una base de datos de niños deportistas en Antiquia del 2018 de morfologia. Con esta base de intentara clasificar el peso en kg por ensima y por debajo de la mediana.

```{r}
Morfo <- read.csv2("C:/Users/jupja/Desktop/UN/TAE/Taller-TAE-2019-2.github.io/Morfologia_ninos_ANT.csv",sep = ";")
Morfo <- Morfo[,-1]
Morfo <- na.omit(Morfo)
peso01 <- rep(0,length(Morfo$Peso.kg.))
peso01[Morfo$Peso.kg. > median(Morfo$Peso.kg.)]<-1
Morfo$peso01 <- peso01
Morfo <- Morfo[,-1]
train <- sample(1:nrow(Morfo),length(Morfo$peso01)*0.70,replace = FALSE)
Morfo.train <- Morfo[train,]
Morfo.test <- Morfo[-train,]

```

>Aplicando Boosting

```{r}
set.seed(0511)
bf <- gbm(peso01~.,Morfo.train,distribution = "bernoulli",n.trees = 5000)
bprobs  <- predict(bf,newdata = Morfo.test,n.trees = 5000)
bpredic <- ifelse(bprobs >0.5,1,0)
table(bpredic,Morfo.test$peso01)
```
Podemos concluir con lo anterior que este modelo puede clasificar un 96.62% de la veces el peso de los niños por encima y por debajo de la mediana.

>regresión logistica

```{r}
logit.mor <- glm(peso01~.,data = Morfo.train,family = "binomial")
logit.probs <- predict(logit.mor,newdata = Morfo.test,type = "response")
logit.pred <- ifelse(logit.probs >0.5 ,1,0)
table(logit.pred,Morfo.test$peso01)
```
Tenemos un error de clasifación de 3.83%. 

>bosques aleatorios

```{r}
library(randomForest)

forest.morfo <- randomForest(peso01~.,data = Morfo.test,mtry=5)
for.probs <- predict(forest.morfo,newdata = Morfo.test)
for.predic <- ifelse(for.probs >0.5,1,0)
matrixx <- confusionMatrix(as.factor(for.predic),as.factor(Morfo.test$peso01))
matrixx
```
Concluimos que el error de predicción 0.09% para clasificar los pesos por encima y por debajo de la mediana.

>regresión lineal.

```{r}
lm.morf <- lm(peso01~.,Morfo.train)
probs.morf <- predict(lm.morf,Morfo.test)  
predic.morf <- ifelse(probs.morf>0.5,1,0)
matrixx <- confusionMatrix(as.factor(predic.morf),as.factor(Morfo.test$peso01))
matrixx
```
Observamos que el modelo tiene un error de predicción de 6.02%.


**Conclusión:** El mejor modelo para la predicción son los bosques aleatorios con un error de 0.09% a comparación de los demas. 
 


